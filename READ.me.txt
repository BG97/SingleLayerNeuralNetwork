1. Does your network reach 0 training error? 
Yes
2. Can you make your program into stochastic gradient descent (SGD)?
Yes
3. Does SGD give lower test error than full gradient descent?
Yes
4. What happens if change the activation to sign? Will the same algorithm
work? If not what will you change to make the algorithm converge to a local
minimum?
No, we need to change the algorithm